{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Large Scale Machine Learning\n",
    "So far, we were able to load the entire data in memory and make models. But this might not be possible in many real life situations.\n",
    "\n",
    "We will now look at how\n",
    "\n",
    "* to handle such large-scale data\n",
    "* do incremental preprocessing and learning\n",
    "    * fit() vs partial_fit()\n",
    "* Combining preprocessing and incremental learning.\n",
    "\n",
    "\n",
    "#### Incremental Learning\n",
    "the idea is to process data in batches and update the model parameters for each batch. This way of learning is referred to as **incremental learning**. it can be implemented in two cases \n",
    "* For **out-of-memory** datsets. where its not possible to load the entire data into the RM at once, one can load the data in chunks and fit the training model for each chunk of data. \n",
    "* for ML tasks where a new batch of data comes with time, re-training the model with the previous and new batch of data is a computationally expensive process. \n",
    "> instead retraining the model with the entire set of data, one can employ an incremental learning approach, where the model parameters are updated with the new batch data \n",
    "\n",
    "##### partial_fit() : \n",
    "```py\n",
    "partial_fit(X, y, [classes], [sample_weight])\n",
    "\n",
    "# classes ==> list of classes. its recommended to supply the list of classes the very first time when we call the partial_fit method. cause it may happen that in the 1st chunk some classes are not present. \n",
    "```\n",
    "\n",
    "The following estimators implement partial_fit method;\n",
    "\n",
    "* Classification:\n",
    "    * MultinomialNB\n",
    "    * BernoulliNB\n",
    "    * SGDClassifier (can be used to implement different classifiers)\n",
    "    * Perceptron\n",
    "\n",
    "* Regression:\n",
    "    * SGDRegressor\n",
    "* Clustering:\n",
    "    * MiniBatchKMeans\n",
    "\n",
    "> **SGDRegressor** and **SGDClassifier** are commonly used for large scale dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### fit() vs partial_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Traditional Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = make_classification(\n",
    "    n_samples=50000, n_features=10, n_classes=3, n_clusters_per_class=1\n",
    ")\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = SGDClassifier(max_iter=1000, tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(tol=0.01)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8470823529411765\n"
     ]
    }
   ],
   "source": [
    "train_score = clf1.score(x_train, y_train)\n",
    "print(\"Training score: \", train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8517333333333333\n"
     ]
    }
   ],
   "source": [
    "test_score = clf1.score(x_test, y_test)\n",
    "print(\"Training score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      2488\n",
      "           1       0.84      0.83      0.84      2557\n",
      "           2       0.89      0.85      0.87      2455\n",
      "\n",
      "    accuracy                           0.85      7500\n",
      "   macro avg       0.85      0.85      0.85      7500\n",
      "weighted avg       0.85      0.85      0.85      7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf1.predict(x_test)\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Incremental Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "train_data = np.concatenate((x_train, y_train[:, np.newaxis]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11003047,  0.38908167,  1.47860953, -0.28270276, -0.31148655,\n",
       "         0.16744432,  1.9966384 ,  0.55197083, -0.56721298, -1.0812275 ,\n",
       "         1.        ],\n",
       "       [ 0.68697399, -1.04758773,  0.04478718, -0.04564442,  0.22511452,\n",
       "        -0.65409864,  2.6238179 , -1.10444198, -1.55020072, -1.17506703,\n",
       "         1.        ],\n",
       "       [ 0.22031978,  1.7393718 , -0.2605469 , -1.48837971, -2.07845681,\n",
       "        -0.25352852, -0.84557823,  1.796273  ,  0.07208196,  0.94706743,\n",
       "         2.        ],\n",
       "       [-1.24892515, -0.39061413, -0.41031182,  0.03868295, -0.22756571,\n",
       "         1.32660628,  0.52983493, -2.17001691,  1.02997175, -1.07805313,\n",
       "         1.        ],\n",
       "       [-0.04011214, -2.2423575 , -0.23955815,  0.37060199, -1.26875087,\n",
       "         0.08466208,  1.6386385 ,  0.92970865, -0.51408611, -0.12544258,\n",
       "         1.        ]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.asarray(train_data)\n",
    "np.savetxt(\"train_data.csv\", a, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = SGDClassifier(max_iter=1000, tol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After iter # 1\n",
      "[[ 24.86977182  -0.76404621 -14.13044271  -2.45674511   8.40506152\n",
      "  -25.38348618  29.28701781  20.56655709 -33.95172773  16.64349898]\n",
      " [-12.28891561 -16.07376281  10.70895973  13.35830589  -2.93840371\n",
      "   13.29483941  14.52830124  18.49953659   6.99146449   9.12941022]\n",
      " [  7.01890264  -5.51692509  -1.14402555   9.10928025  11.58532188\n",
      "   -8.62636488 -48.12690465  -8.91773147   9.4458253   -0.83175161]]\n",
      "[-106.38130377  -22.123142     -0.42707729]\n",
      "After iter # 2\n",
      "[[ 17.32319306 -19.96940772  17.26280622   4.31857432 -11.53370198\n",
      "  -17.36093809  32.74241067  -4.20670068 -27.81383225 -15.34485822]\n",
      " [-12.25689272   1.7952154  -11.16827132 -13.92941841  13.79337311\n",
      "   13.13806953   9.7813337   -6.26302128   8.56218909  -3.87573571]\n",
      " [  4.99905856  -3.72970971  -1.24280574  -0.70273311  -1.89152705\n",
      "   -6.02667202 -29.7556034   -0.21621234   5.20186526   1.81464476]]\n",
      "[-71.70520108 -15.33757535 -23.43152305]\n",
      "After iter # 3\n",
      "[[ 20.2993236   -8.99253296   8.32998564  -6.10793663  -1.12407878\n",
      "  -20.50460536  32.15747549   6.30969806 -30.49685458  -1.1244968 ]\n",
      " [ -8.77685557   2.91186888  -4.86919295   7.60708632  -1.33921454\n",
      "    9.26194794   1.37847437   0.67477806   8.02938709   0.99893968]\n",
      " [  5.08242808  -6.04561535   1.47139976 -11.98070716  -0.68789343\n",
      "   -5.73921641 -15.29218425 -14.44852054   0.24094435   0.03715205]]\n",
      "[-66.82692725 -17.17791907  -6.87412698]\n",
      "After iter # 4\n",
      "[[  7.97652608   5.92434193  -3.6075557    2.13444264   2.82411729\n",
      "   -7.84222511  20.92509884 -15.11687023 -14.78045436  -1.37893656]\n",
      " [-11.30342305   0.17044143   3.4941591    1.15909146  -2.21523205\n",
      "   12.00152477   4.60429755  -5.06317243   9.38622252  -1.98538571]\n",
      " [ -0.45732095   1.89851904   4.80302773  -1.05049726  -6.32508049\n",
      "    0.05236492 -16.51771033  -1.05567189   6.0159996    2.34222453]]\n",
      "[-51.7147523   -8.19268539  -4.87659183]\n",
      "After iter # 5\n",
      "[[  4.48616176   6.45567662  -3.09899948   1.43309046   1.03793645\n",
      "   -4.17593337  20.81842194  -4.49803059 -11.36637766  -5.0526615 ]\n",
      " [ -6.85943394   2.94932978   6.01743327  -3.85244714  -3.26549651\n",
      "    7.28217164   2.7593042    6.16880413   5.70772919   2.7342481 ]\n",
      " [ -1.951968    -4.91164558   1.82397031   4.87386953  -4.5577479\n",
      "    1.78063343 -10.45997284  -2.05102912   5.41856886   0.56708089]]\n",
      "[-40.4594719  -10.10298665  -4.93890683]\n",
      "After iter # 6\n",
      "[[ 10.26390983  -2.66142338   4.37738469  -0.51325788  -1.27313407\n",
      "  -10.37650123  15.92058816  -0.25807609 -15.30563736  -0.79481703]\n",
      " [ -8.424795     1.52330329  -1.7560272    1.0252778    1.90370727\n",
      "    9.08785467   8.93581343   0.74200744   5.13866178  -1.80711588]\n",
      " [  1.36300294   4.16931233   1.31674943  -3.58013557  -2.42367169\n",
      "   -1.64683654  -8.25377333   0.57164541   1.46582432   4.66841848]]\n",
      "[-29.66082005  -8.62093339  -4.98639069]\n",
      "After iter # 7\n",
      "[[  9.90511685  -1.4400209   -5.1835026   -2.12360811  -2.3106131\n",
      "  -10.07132508  13.14485329   0.25122899 -14.02180063  -4.12354786]\n",
      " [ -5.19182042   0.24189495  -0.0307857    0.52471448  -1.50247876\n",
      "    5.45914511   0.05870137   0.30591608   5.00499643  -0.47605183]\n",
      " [  2.2779871   -2.73991666  -7.08301519   1.13032168  -5.33229716\n",
      "   -2.79319982 -15.36936412  -3.03669649   2.98121049   2.70649843]]\n",
      "[-29.84272867 -10.14020345  -2.42221756]\n",
      "After iter # 8\n",
      "[[ 5.10151808  0.69742822 -0.23149322  1.33582963  0.77042311 -5.12055369\n",
      "   9.33693959  1.03614434 -8.08786741  3.91115476]\n",
      " [-2.85519659  1.3966964  -0.36620137 -3.06225865 -1.07120359  3.10972964\n",
      "   4.17820773  1.44100772  1.35354009 -5.99364463]\n",
      " [ 0.83224929 -3.46318445  0.45308365  2.13670524 -4.46148217 -1.11198989\n",
      "  -9.14371368  6.78300884  2.27978685  0.13357419]]\n",
      "[-27.58991834  -5.37856542  -5.83402136]\n",
      "After iter # 9\n",
      "[[ 3.25500249 -0.45220415 -0.96423718 -6.14304303 -1.33206383 -3.17135317\n",
      "   9.65120147  2.86701287 -6.40679082  2.49779273]\n",
      " [-2.9581785   0.21731527  0.7452764   0.96371609 -1.67080169  3.12536618\n",
      "   0.60691491  1.49837379  2.65823142  1.48836809]\n",
      " [-0.60210162  2.71886771  1.08941821 -0.93079933 -1.36291022  0.4380704\n",
      "  -7.51357808 -3.05609594  3.11795693 -1.30525101]]\n",
      "[-24.31090111  -5.42372901  -5.56864669]\n",
      "After iter # 10\n",
      "[[  3.22497118   0.87232799  -3.63823219   5.27041695   2.05182323\n",
      "   -3.14228436   9.55480313   0.20909513  -6.34519895   1.25508142]\n",
      " [ -2.24762118   0.54492842   0.47814457  -0.11705186  -2.09807356\n",
      "    2.39531221   1.25784977  -0.24590634   1.75089438   1.47230312]\n",
      " [  0.0260076    3.3927564    4.32496862   1.19665416  -2.59354667\n",
      "   -0.32073459 -11.31318941  -0.63144079   3.79211481  -2.11897335]]\n",
      "[-21.49635258  -5.37398365  -3.54128541]\n",
      "After iter # 11\n",
      "[[ 5.75382922e+00 -5.55939311e-01  6.48556602e-01  1.14353112e+00\n",
      "   1.76909056e+00 -5.80577419e+00  9.35570297e+00  3.03665323e-01\n",
      "  -8.72552531e+00 -1.29572852e+00]\n",
      " [-4.04288895e+00 -1.68593542e+00  7.26861354e-03  3.14680956e+00\n",
      "  -1.39629605e+00  4.41143776e+00  6.22996899e+00 -1.25732362e+00\n",
      "   1.81072190e+00  2.20514016e+00]\n",
      " [ 1.16274231e-01  7.39526900e-01  2.64782868e+00  4.57541285e-01\n",
      "   3.79132081e+00 -2.26432914e-01 -4.01812806e+00 -1.89938905e-01\n",
      "   1.24325923e+00  2.08012922e+00]]\n",
      "[-18.79227346  -5.29637922  -2.56155622]\n",
      "After iter # 12\n",
      "[[ 4.74274707  1.93170088 -0.77806647 -2.43241817 -1.22533375 -4.75200157\n",
      "   9.00584215  1.57945216 -7.62891921  0.15398005]\n",
      " [-3.24958068 -0.15731106  0.84080731 -0.23117366  2.08732909  3.52261102\n",
      "   4.112898   -0.702727    1.75727389  0.12081094]\n",
      " [ 0.7825255   0.71220195  1.73661925  2.8568383   2.81691466 -1.01467583\n",
      "  -7.4068159   0.50441086  1.74184864  2.05540597]]\n",
      "[-18.878588    -4.54819474  -2.56820661]\n",
      "After iter # 13\n",
      "[[ 2.67134475 -3.10184046 -0.62177575 -0.47441227  2.37726763 -2.6756047\n",
      "   5.10925944  0.46048759 -4.30937109  1.54287778]\n",
      " [-3.97545916  2.38180218  1.21441828  0.85811725 -1.02493346  4.31811389\n",
      "   5.36461884  1.6024966   2.03744692 -0.35861005]\n",
      " [-0.12652193 -2.15914246  0.21619103  1.58320348 -2.79656283 -0.10343972\n",
      "  -9.11697885  3.22123561  3.19869427 -0.4894079 ]]\n",
      "[-16.58952155  -6.04232219  -1.15891374]\n",
      "After iter # 14\n",
      "[[ 4.09253094 -1.36635439  1.13528583  1.34399144 -1.17921236 -4.15036838\n",
      "   5.84891108 -3.47512178 -5.93441133 -2.68525381]\n",
      " [-3.26980882 -2.72366744  1.74700041 -1.99434057 -1.60446221  3.44982288\n",
      "   0.48630234  2.01583846  3.00053381 -0.72174951]\n",
      " [ 1.02672413  0.29455107  2.93789268  1.63172313  1.81056587 -1.22444633\n",
      "  -5.5972094  -0.18551304  0.89490997  1.75463034]]\n",
      "[-17.26339987  -3.37443569  -2.57947483]\n",
      "After iter # 15\n",
      "[[ 2.19491808  1.76060442  0.19023153 -2.39768744  0.27665071 -2.12574473\n",
      "   7.00029484 -2.151523   -4.48634211  2.31426142]\n",
      " [-2.60887158 -0.15242366 -0.10584851  0.29460243 -0.06984235  2.86127061\n",
      "   4.58219304 -1.13771914  0.97882683 -0.432579  ]\n",
      " [-0.25083026  3.10261601  0.32680346  1.32469152  3.11844392  0.10067837\n",
      "  -6.28495056  0.37883707  2.36342336 -0.21782227]]\n",
      "[-13.37462699  -4.66976465  -3.16560302]\n",
      "After iter # 16\n",
      "[[ 3.63087097 -0.92415762 -0.30794556  0.19785625 -0.86174503 -3.65540767\n",
      "   6.22160501  1.74838223 -5.61335666  2.04278983]\n",
      " [-3.52532362  0.75511507 -3.09342807  0.21395909  0.79419089  3.75082173\n",
      "   1.73573178  0.01701938  2.82624758 -0.15341238]\n",
      " [ 1.23229521  2.55285537 -0.50839094 -0.71308641  0.60208093 -1.4694663\n",
      "  -6.71252035  0.69029629  1.07227913  0.35005093]]\n",
      "[-15.24716913  -4.08999648  -0.15148035]\n",
      "After iter # 17\n",
      "[[ 3.26164387  1.29111326  0.4705173  -0.78452307 -2.85790329 -3.31501599\n",
      "   4.38083158  1.90030906 -4.63489528  0.31728659]\n",
      " [-2.41243274 -0.75023263 -0.33192749  1.63863617  0.16613618  2.62171739\n",
      "   3.30751445  2.06119697  1.21880814  0.53153836]\n",
      " [ 0.75110102 -1.34725254 -1.75391457  0.02670098  2.77783288 -0.92319649\n",
      "  -5.1531646  -2.54246925  1.01183731  0.81125966]]\n",
      "[-14.04693417  -2.41484409  -4.13399832]\n",
      "After iter # 18\n",
      "[[ 3.90321258  1.16539505 -0.80992408  1.31571777 -0.36348872 -4.00701503\n",
      "   3.70278761  1.55461376 -5.02704024 -0.89525549]\n",
      " [-1.89251741 -2.95264218  0.64944664 -1.10765403 -0.59542057  2.03865186\n",
      "   1.89884203  0.4308231   1.19093102 -0.42720616]\n",
      " [ 0.35581051 -0.67535247  0.19023914 -0.42913739 -0.7202538  -0.47814823\n",
      "  -4.01487533 -0.55173601  1.01033112  1.84208772]]\n",
      "[-13.5231631   -4.64999844  -0.83016567]\n",
      "After iter # 19\n",
      "[[ 2.08557001 -1.01908295  0.30784886 -0.90760705  1.24839992 -2.01669368\n",
      "   6.77297688  0.68677126 -4.30381027  1.12454812]\n",
      " [-1.99319555 -0.41035584 -0.43392296  1.75492166  2.02345325  2.15187004\n",
      "   2.1836305   0.56623113  1.19227736  0.03189149]\n",
      " [ 0.45408944 -0.29392547  0.48097481 -0.34922727 -0.5445698  -0.61729798\n",
      "  -5.3968214   1.11652409  1.3815087  -2.84569473]]\n",
      "[-11.93632326  -3.0943981   -1.39979885]\n",
      "After iter # 20\n",
      "[[ 2.77060354 -2.00471315  0.78375134 -1.72073874 -0.64440302 -2.81056963\n",
      "   3.92839532  1.2993192  -4.00699073  0.66911831]\n",
      " [-2.23903839  1.62377343 -0.00660282  0.77118715  0.24542496  2.38551589\n",
      "   1.22799979 -0.28813052  1.75265965  0.56463461]\n",
      " [-0.30032452 -2.95555605 -0.62314713 -1.88944124  0.56268642  0.19611005\n",
      "  -4.61133259  0.66922803  1.84661482 -0.62785257]]\n",
      "[-12.39761808  -3.58644649  -0.9202518 ]\n",
      "After iter # 21\n",
      "[[ 2.34599683  1.74796271 -0.39332943 -0.10252021  0.66932554 -2.3328109\n",
      "   5.13969236  1.33284822 -4.00475802 -1.40851728]\n",
      " [-1.92994411 -0.11102233  0.61352765 -1.76420738  1.36897252  2.10524538\n",
      "   2.9496164   2.378824    0.87260243 -0.28998091]\n",
      " [ 1.88139735  1.00796062  0.04987844  1.61711436 -0.06604516 -2.13242546\n",
      "  -5.96544299  2.37361644  0.19197999 -0.84335511]]\n",
      "[-11.95216571  -1.74219988  -1.91130951]\n",
      "After iter # 22\n",
      "[[ 2.95097508  0.37270372  1.09303174 -0.4717901  -0.59823235 -2.95877043\n",
      "   5.52495644  0.06459012 -4.72027001 -0.71607214]\n",
      " [-1.35652487  1.02823024  0.29167109 -2.20472905 -1.17656551  1.40094392\n",
      "  -0.96514863  1.60094311  1.63854602  0.03437794]\n",
      " [ 0.51201389  1.41392437 -0.31475054 -0.16305757 -1.36819293 -0.61322099\n",
      "  -2.89172687  0.03835053  0.48018098 -1.03379037]]\n",
      "[-11.0686929   -3.9631322   -0.16455528]\n",
      "After iter # 23\n",
      "[[ 2.48016805  0.20936219  0.41164858  0.06400803 -1.45856175 -2.46196082\n",
      "   5.59817962  0.69955932 -4.28931539  0.70590597]\n",
      " [-1.85752839  1.661353   -0.61076455  0.2636753  -1.10337009  2.02513869\n",
      "   2.79601237  1.00523317  0.8543452  -0.85709784]\n",
      " [-0.4480504   0.41140804 -2.2708127   0.85162063  0.88743401  0.3523692\n",
      "  -4.57392051  1.61489686  1.97696492 -1.9525432 ]]\n",
      "[-11.8959868   -2.68514561  -1.03220064]\n",
      "After iter # 24\n",
      "[[ 2.77570991  0.04222646  0.5675418   1.73174096  0.19305108 -2.78966264\n",
      "   4.94153867  1.3247325  -4.35378672  0.17657855]\n",
      " [-0.35438029  0.12101726  1.89461492 -1.89604821 -0.29383693  0.38163779\n",
      "   0.35145139 -0.08282377  0.22439374 -0.50074827]\n",
      " [ 0.22843609  0.63710137  0.97352136 -0.39948968  2.45113182 -0.33093923\n",
      "  -3.50151453 -0.11092275  0.96039028  0.14389436]]\n",
      "[-12.31678455  -3.51027044  -1.45677314]\n",
      "After iter # 25\n",
      "[[ 2.22560225 -0.77637891 -0.57422765  0.15764256  0.43157385 -2.22458957\n",
      "   4.43262596  2.4358495  -3.64965877  0.17113158]\n",
      " [-1.95062097 -0.68717737  1.62989795  0.37613678 -1.68280774  2.10192039\n",
      "   1.98329783 -0.64606405  1.21866844 -1.23818361]\n",
      " [ 1.10067906  1.35564546  1.2553404  -1.0194244   0.23741617 -1.29522559\n",
      "  -5.32876243 -0.67588586  0.732755    0.33304968]]\n",
      "[-11.13944367  -2.7255955   -0.69753403]\n",
      "After iter # 26\n",
      "[[ 2.77140417 -1.29197311 -0.15140024  1.67528864 -0.48806572 -2.79387672\n",
      "   4.60451824 -0.8459216  -4.23590237  2.63642298]\n",
      " [-1.30112472  0.20051788  0.27624908 -1.11686715  0.7495654   1.41213571\n",
      "   1.71197066  1.53477206  0.68161697  0.01087591]\n",
      " [ 0.45226173 -0.99058122 -1.12469159 -0.68855929  0.12975006 -0.57326667\n",
      "  -3.77307928 -0.18324314  0.83539607 -0.24932069]]\n",
      "[-11.10313113  -2.7316941   -1.08233687]\n",
      "After iter # 27\n",
      "[[ 2.26810483  1.00472071 -0.32402423 -0.47419484 -0.48982589 -2.27758121\n",
      "   4.11207757 -0.69730924 -3.58263493  0.91949091]\n",
      " [-1.1740418   1.29124046 -0.27131307  0.5689029  -0.11322609  1.2483443\n",
      "   0.54738416  1.77618914  0.9515759  -0.16712884]\n",
      " [-0.0990016  -1.66226254 -0.59055133 -0.16921624  0.2304152   0.00983671\n",
      "  -3.63359496  0.43591384  1.32186099  0.3580726 ]]\n",
      "[-11.09831513  -3.44052674  -0.75640264]\n",
      "After iter # 28\n",
      "[[ 1.40606664 -1.58840807  0.63904552  0.42782184 -0.49230957 -1.38688041\n",
      "   3.51553827  1.592867   -2.54704415 -1.01840469]\n",
      " [-0.82403412 -0.60677171 -0.14045327  0.92542565  1.37506606  0.88978643\n",
      "   0.90864559  0.01751641  0.49093121  0.63780122]\n",
      " [ 0.75449804  0.85567868  0.05412398 -0.59281284 -0.39020208 -0.85378838\n",
      "  -2.33912748  0.51539237  0.0590398   1.16818836]]\n",
      "[-9.3418723  -2.73537319 -0.77112358]\n",
      "After iter # 29\n",
      "[[ 1.96405104  0.22816027 -1.37055851  0.8490897  -0.13081615 -1.95051775\n",
      "   4.39908438  0.7393314  -3.3852039   1.36142182]\n",
      " [-1.64885853  0.04417159  0.5150056   0.27676613 -0.68995231  1.7571542\n",
      "   0.92080566  0.22417825  1.28511858  0.68142671]\n",
      " [ 0.97862448 -0.74919587  0.02399507  0.62536979  2.22746621 -1.10244219\n",
      "  -2.84244164 -0.48091953  0.01195114  1.04639967]]\n",
      "[-8.65087579 -2.71880887 -0.119235  ]\n",
      "After iter # 30\n",
      "[[ 1.75538511  0.70166128 -3.25449147 -0.05766108 -0.69609689 -1.761612\n",
      "   3.22521237 -0.0162629  -2.7871638   1.19589579]\n",
      " [-1.56186743  0.53216605 -1.00167361  0.5881638   0.24355541  1.70814036\n",
      "   2.55691995 -0.00485537  0.64886978 -0.37966154]\n",
      " [ 1.31487962 -0.22125124 -0.05078769  0.69061784 -0.62070049 -1.45339544\n",
      "  -2.74539025 -0.29523741 -0.34623391  0.07109694]]\n",
      "[-8.64623047 -3.68065847 -0.1529759 ]\n",
      "After iter # 31\n",
      "[[ 1.96410827e+00  7.99620181e-01 -5.47377876e-03 -1.91939559e-01\n",
      "  -1.12360396e+00 -1.96158153e+00  3.97479022e+00  6.02718673e-01\n",
      "  -3.24209435e+00 -2.82514785e-01]\n",
      " [-1.51770165e+00  3.27463188e-01 -1.66597703e+00  8.41200763e-02\n",
      "   7.16041740e-01  1.61901153e+00  9.10354378e-01  6.37605957e-01\n",
      "   1.16170739e+00  2.14717598e+00]\n",
      " [ 9.89503949e-04  3.02083573e-01  6.68103418e-02 -7.11908532e-01\n",
      "  -4.20780015e-01 -5.34052322e-02 -2.01917190e+00 -6.63363917e-01\n",
      "   6.80349419e-01 -7.82427641e-01]]\n",
      "[-9.59027658 -2.08686117 -2.68307616]\n",
      "After iter # 32\n",
      "[[ 2.48534905  0.13084753  0.10054287  0.61544958 -0.16500163 -2.51509917\n",
      "   3.75919519 -0.38647189 -3.67382133 -0.55640049]\n",
      " [-1.97958288 -0.22589305  0.24889241 -0.12542385  0.92498918  2.13245378\n",
      "   1.98671964 -0.92013573  1.24554409  1.0620229 ]\n",
      " [ 0.48949226  0.72380047 -0.44229649 -0.02929342  0.7238766  -0.60535412\n",
      "  -3.50126754 -0.98324984  0.70764875 -0.18049815]]\n",
      "[-6.23426559 -3.319488   -2.03651154]\n",
      "After iter # 33\n",
      "[[ 1.6323896  -0.93501063 -0.01485152 -1.05234497 -0.17833837 -1.61975681\n",
      "   3.7096261   0.73207665 -2.83157539  1.67293299]\n",
      " [-1.12469329  0.33487511 -0.29009285 -1.20314197 -0.60731191  1.20791249\n",
      "   0.98862713  0.60644383  0.7549311   1.24902326]\n",
      " [ 0.53764975 -1.16154636  0.48110564 -0.17922565  0.41342403 -0.65304062\n",
      "  -3.3880382  -0.08322032  0.62283472  0.42623392]]\n",
      "[-7.15586579 -2.40769426 -1.42823261]\n",
      "After iter # 34\n",
      "[[ 1.97025902  0.91701466  0.26034664 -0.50526452  0.03552097 -1.94718164\n",
      "   4.77935523 -0.02234945 -3.5195228   0.57433868]\n",
      " [-0.78844776 -0.37010612  2.66717018 -0.15332557  0.67960165  0.86393936\n",
      "   1.35443956 -0.09105476  0.30607025 -1.08159989]\n",
      " [ 0.075219   -0.4414352  -1.20765814  2.06120197  0.77791571 -0.15405523\n",
      "  -2.89139669 -0.50535301  0.90281309  0.68681852]]\n",
      "[-9.18932582 -2.4111107  -1.4264689 ]\n",
      "After iter # 35\n",
      "[[ 2.01877286e+00 -1.50816686e-01 -9.09874766e-01  1.65589362e-01\n",
      "  -5.75346517e-01 -2.05036467e+00  2.76710892e+00 -6.61830207e-02\n",
      "  -2.88750573e+00  9.19982118e-04]\n",
      " [-1.49984314e+00  7.47122304e-02 -1.90018153e-01  3.99799051e-01\n",
      "   5.36774739e-01  1.62152738e+00  1.73123465e+00 -2.99985009e-01\n",
      "   8.67442722e-01  6.58963993e-01]\n",
      " [-8.45060165e-02 -2.54108086e-01  6.79759270e-01 -8.01303816e-01\n",
      "   1.67155214e+00 -6.34761887e-03 -3.67009646e+00  5.04273484e-01\n",
      "   1.32014803e+00  1.09921778e+00]]\n",
      "[-8.62284491 -2.1329464  -0.58879003]\n",
      "After iter # 36\n",
      "[[ 2.14920802  1.11234496  0.68517941 -0.51396464 -1.83809308 -2.19412034\n",
      "   2.51096974 -1.38783578 -2.92731864 -0.06492071]\n",
      " [-1.00435976  1.36149027  0.09547034  1.23605489 -0.26078896  1.08570127\n",
      "   1.15377539  0.673315    0.58274444 -0.30263833]\n",
      " [ 0.23243615  0.7459762   0.37897671 -0.32520503 -0.88984911 -0.28200131\n",
      "  -1.45235491 -0.00807375  0.26509338  0.60533412]]\n",
      "[-8.06797458 -2.68053828 -1.40918631]\n",
      "After iter # 37\n",
      "[[ 1.20825491 -0.74758208  0.89327627  0.07394439  0.37818083 -1.17319988\n",
      "   3.73692953  0.20056574 -2.4302975   0.92699341]\n",
      " [-1.66245463 -0.78793905  0.13733131  0.36599093  1.43778072  1.77729867\n",
      "   1.14646731 -0.68842877  1.22213477  0.43874818]\n",
      " [ 0.69377565  0.58108489  0.33106227  0.92229724 -0.21717344 -0.80732827\n",
      "  -3.00894674  0.05029089  0.34381859 -0.37264727]]\n",
      "[-7.53168553 -2.68865959 -1.38904171]\n",
      "After iter # 38\n",
      "[[ 1.53433117  0.41715509  0.25578479  0.29660706 -0.23166713 -1.53648278\n",
      "   2.94596939 -0.2012403  -2.4789991  -0.31161347]\n",
      " [-1.31759188 -0.04207829  0.73439353  0.314171   -0.15120597  1.42193425\n",
      "   1.42232414  0.88905505  0.79528664  0.66494666]\n",
      " [ 1.05980964 -0.69962059 -0.11571196 -1.52228601  0.11804967 -1.18509236\n",
      "  -2.73866328  0.12490202 -0.10163916 -0.85790126]]\n",
      "[-7.53198458 -2.17262672 -0.87302395]\n",
      "After iter # 39\n",
      "[[ 1.36490457 -0.09705472  0.49733405 -1.32594904  0.55342146 -1.37668922\n",
      "   2.24005753 -0.14798141 -2.07683471 -0.43783969]\n",
      " [-1.19879084 -0.21813307 -0.52954414  0.59556241  0.45134426  1.31463469\n",
      "   2.10034134 -0.30529605  0.45153142 -0.41744331]\n",
      " [ 0.04917906 -1.00171112 -1.24527852  1.31586657 -0.0280051  -0.11875434\n",
      "  -2.58570466 -0.11083889  0.82486903 -0.02013278]]\n",
      "[-7.27144355 -2.6721392  -1.37870095]\n",
      "After iter # 40\n",
      "[[ 1.4987751  -0.5679761  -0.51997296 -0.26480695 -0.04353337 -1.49476027\n",
      "   3.11355276 -1.2423166  -2.50113267  0.27080889]\n",
      " [-0.78704993  1.52961823  0.93654406  0.47998126  0.26888667  0.86273093\n",
      "   1.3645017  -0.30171857  0.30132224 -0.0316837 ]\n",
      " [-0.31152623 -0.00672188 -0.24435192  0.06628846  0.45585914  0.23671135\n",
      "  -3.49981195  0.96453489  1.48240793  1.27057573]]\n",
      "[-6.76982431 -2.41837023 -0.64187301]\n",
      "After iter # 41\n",
      "[[ 1.80629918e+00 -8.34475822e-01 -2.47496649e-01  3.50610778e-03\n",
      "   2.94464906e-01 -1.80551762e+00  3.59596481e+00  1.53045961e-02\n",
      "  -2.96153894e+00  3.43661389e-01]\n",
      " [-1.59979507e+00  6.29377195e-01 -4.08863550e-01  8.08466992e-01\n",
      "  -9.25399643e-01  1.70629490e+00  9.48414993e-01  3.64044245e-01\n",
      "   1.22831755e+00  6.47702186e-01]\n",
      " [-2.65582050e-01 -7.83551547e-01 -5.13604215e-01  1.87416022e-01\n",
      "   2.76574948e-01  2.14732019e-01 -2.48504022e+00 -4.22190470e-01\n",
      "   1.09553841e+00 -1.26239793e+00]]\n",
      "[-7.01773519 -2.40880017 -0.65247566]\n",
      "After iter # 42\n",
      "[[ 1.14686086  0.15680184 -0.56869181 -0.14653545 -0.17322974 -1.14281279\n",
      "   2.42011793 -0.0751491  -1.92656111  0.21275473]\n",
      " [-1.24561823  0.20236544  0.74422911 -0.60054523  0.80604648  1.36982352\n",
      "   2.33031263 -0.1142681   0.41925571 -0.05033215]\n",
      " [ 0.13215575 -0.33594008  1.62995513  1.05566616  0.46852395 -0.20930561\n",
      "  -2.7139721   1.00197071  0.78784153 -1.3521962 ]]\n",
      "[-7.94582636 -1.70331595 -1.35509285]\n",
      "After iter # 43\n",
      "[[ 1.56316679 -0.05034181  0.7939451   0.53842454 -0.17992234 -1.57320989\n",
      "   2.69860165 -0.01572654 -2.42344051 -0.46651419]\n",
      " [-1.18986475 -0.37603166  0.01007274 -0.36469348 -0.20904082  1.29000912\n",
      "   1.5125982  -0.21007591  0.64120821  0.20977822]\n",
      " [ 0.18356658 -0.37798153 -0.91594491  0.10812373  0.77964648 -0.2491963\n",
      "  -2.16827046 -0.08273402  0.55395441  0.58532263]]\n",
      "[-7.24736939 -2.63221425 -2.50100038]\n"
     ]
    }
   ],
   "source": [
    "chunksize = 1000\n",
    "iter = 1\n",
    "\n",
    "for train_df in pd.read_csv(\"train_data.csv\", chunksize=chunksize, iterator=True):\n",
    "\n",
    "    if iter == 1:\n",
    "        # In the first iteration, we are specifying all possible class labels\n",
    "        x_train_partial = train_df.iloc[:, 0:10]\n",
    "        y_train_partial = train_df.iloc[:, 10]\n",
    "        clf2.partial_fit(x_train_partial, y_train_partial, classes = np.array([0, 1, 2]))\n",
    "\n",
    "    else:\n",
    "        x_train_partial = train_df.iloc[:, 0:10]\n",
    "        y_train_partial = train_df.iloc[:, 10]\n",
    "        clf2.partial_fit(x_train_partial, y_train_partial)\n",
    "\n",
    "    print(\"After iter #\", iter)\n",
    "    print(clf2.coef_)\n",
    "    print(clf2.intercept_)\n",
    "    iter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score:  0.8361333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Computer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "test_score = clf2.score(x_test, y_test)\n",
    "print(\"Training score: \", test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85      2488\n",
      "           1       0.77      0.88      0.82      2557\n",
      "           2       0.94      0.76      0.84      2455\n",
      "\n",
      "    accuracy                           0.84      7500\n",
      "   macro avg       0.85      0.84      0.84      7500\n",
      "weighted avg       0.85      0.84      0.84      7500\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Computer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but SGDClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf2.predict(x_test)\n",
    "cr = classification_report(y_test, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Incremental preprocessing example\n",
    "\n",
    "`CountVectorizer` vs `HashingVectorizer`\n",
    "* CountVectorizer and HashingVectorizer both perform the task of vectorizing text data\n",
    "* HashingVectorizer does't store the resulting vocabulary, therefore it can be used to learn from data that doesn't fit into main memory. Each mini batch is vectorized using HashingVectorizer so as to guarantee that that the input space of the vvectorizer has the same dimensionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['Russell was raised by his paternal grandparents after his unconventional parents both died young.', \n",
    "        'He was discontented living with his grandparents, but enjoyed four happy years at Winchester College.',\n",
    "        'His academic education came to a sudden end when he was sent down from Balliol College, Oxford, probably because authorities there had suspicions concerning the nature of his relationship with the future poet Lionel Johnson.',\n",
    "        'He always bitterly resented his treatment by Oxford.']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0]\n",
      " [1 0 1]]\n",
      "['am', 'boy', 'indian']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Computer\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "test_text = ['I am a boy', 'I am indian']\n",
    "c_vectorizer = CountVectorizer()\n",
    "test_text_x = c_vectorizer.fit_transform(test_text)\n",
    "print(test_text_x.toarray())\n",
    "print(c_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "c_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_c = c_vectorizer.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['academic',\n",
       " 'after',\n",
       " 'always',\n",
       " 'at',\n",
       " 'authorities',\n",
       " 'balliol',\n",
       " 'because',\n",
       " 'bitterly',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'college',\n",
       " 'concerning',\n",
       " 'died',\n",
       " 'discontented',\n",
       " 'down',\n",
       " 'education',\n",
       " 'end',\n",
       " 'enjoyed',\n",
       " 'four',\n",
       " 'from',\n",
       " 'future',\n",
       " 'grandparents',\n",
       " 'had',\n",
       " 'happy',\n",
       " 'he',\n",
       " 'his',\n",
       " 'johnson',\n",
       " 'lionel',\n",
       " 'living',\n",
       " 'nature',\n",
       " 'of',\n",
       " 'oxford',\n",
       " 'parents',\n",
       " 'paternal',\n",
       " 'poet',\n",
       " 'probably',\n",
       " 'raised',\n",
       " 'relationship',\n",
       " 'resented',\n",
       " 'russell',\n",
       " 'sent',\n",
       " 'sudden',\n",
       " 'suspicions',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'treatment',\n",
       " 'unconventional',\n",
       " 'was',\n",
       " 'when',\n",
       " 'winchester',\n",
       " 'with',\n",
       " 'years',\n",
       " 'young']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 56)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "        0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "        1, 0, 1, 0, 1, 2, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "        1, 2, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_c.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'russell': 41,\n",
       " 'was': 50,\n",
       " 'raised': 38,\n",
       " 'by': 10,\n",
       " 'his': 27,\n",
       " 'paternal': 35,\n",
       " 'grandparents': 23,\n",
       " 'after': 1,\n",
       " 'unconventional': 49,\n",
       " 'parents': 34,\n",
       " 'both': 8,\n",
       " 'died': 14,\n",
       " 'young': 55,\n",
       " 'he': 26,\n",
       " 'discontented': 15,\n",
       " 'living': 30,\n",
       " 'with': 53,\n",
       " 'but': 9,\n",
       " 'enjoyed': 19,\n",
       " 'four': 20,\n",
       " 'happy': 25,\n",
       " 'years': 54,\n",
       " 'at': 3,\n",
       " 'winchester': 52,\n",
       " 'college': 12,\n",
       " 'academic': 0,\n",
       " 'education': 17,\n",
       " 'came': 11,\n",
       " 'to': 47,\n",
       " 'sudden': 43,\n",
       " 'end': 18,\n",
       " 'when': 51,\n",
       " 'sent': 42,\n",
       " 'down': 16,\n",
       " 'from': 21,\n",
       " 'balliol': 5,\n",
       " 'oxford': 33,\n",
       " 'probably': 37,\n",
       " 'because': 6,\n",
       " 'authorities': 4,\n",
       " 'there': 46,\n",
       " 'had': 24,\n",
       " 'suspicions': 44,\n",
       " 'concerning': 13,\n",
       " 'the': 45,\n",
       " 'nature': 31,\n",
       " 'of': 32,\n",
       " 'relationship': 39,\n",
       " 'future': 22,\n",
       " 'poet': 36,\n",
       " 'lionel': 29,\n",
       " 'johnson': 28,\n",
       " 'always': 2,\n",
       " 'bitterly': 7,\n",
       " 'resented': 40,\n",
       " 'treatment': 48}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 41)\t1\n",
      "  (0, 50)\t1\n",
      "  (0, 38)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 27)\t2\n",
      "  (0, 35)\t1\n",
      "  (0, 23)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 49)\t1\n",
      "  (0, 34)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 55)\t1\n",
      "  (1, 50)\t1\n",
      "  (1, 27)\t1\n",
      "  (1, 23)\t1\n",
      "  (1, 26)\t1\n",
      "  (1, 15)\t1\n",
      "  (1, 30)\t1\n",
      "  (1, 53)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 20)\t1\n",
      "  (1, 25)\t1\n",
      "  (1, 54)\t1\n",
      "  :\t:\n",
      "  (2, 5)\t1\n",
      "  (2, 33)\t1\n",
      "  (2, 37)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 4)\t1\n",
      "  (2, 46)\t1\n",
      "  (2, 24)\t1\n",
      "  (2, 44)\t1\n",
      "  (2, 13)\t1\n",
      "  (2, 45)\t2\n",
      "  (2, 31)\t1\n",
      "  (2, 32)\t1\n",
      "  (2, 39)\t1\n",
      "  (2, 22)\t1\n",
      "  (2, 36)\t1\n",
      "  (2, 29)\t1\n",
      "  (2, 28)\t1\n",
      "  (3, 10)\t1\n",
      "  (3, 27)\t1\n",
      "  (3, 26)\t1\n",
      "  (3, 33)\t1\n",
      "  (3, 2)\t1\n",
      "  (3, 7)\t1\n",
      "  (3, 40)\t1\n",
      "  (3, 48)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`HashingVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.70710678  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.         -0.70710678  0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.70710678  0.          0.\n",
      "   0.          0.          0.         -0.70710678  0.          0.\n",
      "   0.          0.          0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "test_text = ['I am a boy', 'I am indian']\n",
    "h_vectorizer = HashingVectorizer(n_features=30)\n",
    "test_text_x = h_vectorizer.fit_transform(test_text)\n",
    "print(test_text_x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 50)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "h_vectorizer = HashingVectorizer(n_features=50)\n",
    "X_h = h_vectorizer.fit_transform(text)\n",
    "X_h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t-0.2672612419124244\n",
      "  (0, 6)\t0.2672612419124244\n",
      "  (0, 11)\t-0.2672612419124244\n",
      "  (0, 19)\t-0.2672612419124244\n",
      "  (0, 21)\t0.2672612419124244\n",
      "  (0, 23)\t-0.2672612419124244\n",
      "  (0, 24)\t0.5345224838248488\n",
      "  (0, 28)\t0.2672612419124244\n",
      "  (0, 30)\t0.2672612419124244\n",
      "  (0, 40)\t-0.2672612419124244\n",
      "  (0, 42)\t0.0\n",
      "  (0, 49)\t0.2672612419124244\n"
     ]
    }
   ],
   "source": [
    "print(X_h[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining preprocessing and fiting in incremental learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from io import StringIO, BytesIO, TextIOWrapper\n",
    "from zipfile import ZipFile\n",
    "import urllib.request\n",
    "\n",
    "response = urllib.request.urlopen('https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip')\n",
    "zipfile = ZipFile(BytesIO(response.read()))\n",
    "\n",
    "data = TextIOWrapper(zipfile.open('sentiment labelled sentences/amazon_cells_labelled.txt'), encoding='utf-8')\n",
    "df = pd.read_csv(data, sep = '\\t')\n",
    "df.columns = ['review', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have to jiggle the plug to get it to line up...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0                        Good case, Excellent value.          1\n",
       "1                             Great for the jawbone.          1\n",
       "2  Tied to charger for conversations lasting more...          0\n",
       "3                                  The mic is great.          1\n",
       "4  I have to jiggle the plug to get it to line up...          0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>The screen does get smudged easily because it ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>What a piece of junk.. I lose more calls on th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Item Does Not Match Picture.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>The only thing that disappoint me is the infra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>You can not answer calls with the unit, never ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "994  The screen does get smudged easily because it ...          0\n",
       "995  What a piece of junk.. I lose more calls on th...          0\n",
       "996                       Item Does Not Match Picture.          0\n",
       "997  The only thing that disappoint me is the infra...          0\n",
       "998  You can not answer calls with the unit, never ...          0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 999 entries, 0 to 998\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     999 non-null    object\n",
      " 1   sentiment  999 non-null    int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[:, 'sentiment'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = df.loc[:, 'review']\n",
    "y = df.loc[:,'sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(799,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = HashingVectorizer()\n",
    "classifier = SGDClassifier(penalty='l2', loss='hinge') # SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Iteration 1 of `partial_fit()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_part1_hashed = vectorizer.fit_transform(X_train[0:400])\n",
    "y_train_part1 = y_train[0:400]\n",
    "all_classes = np.unique(df.loc[:, 'sentiment'])\n",
    "\n",
    "classifier.partial_fit(\n",
    "    X_train_part1_hashed, y_train_part1, classes = all_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.7\n"
     ]
    }
   ],
   "source": [
    "X_test_hashed = vectorizer.transform(X_test)\n",
    "test_score = classifier.score(X_test_hashed, y_test)\n",
    "print(\"Test score: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Iteration 2 of partial_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_part2_hashed = vectorizer.fit_transform(X_train[400:])\n",
    "y_train_part2 = y_train[400:]\n",
    "\n",
    "classifier.partial_fit(X_train_part2_hashed, y_train_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score:  0.765\n"
     ]
    }
   ],
   "source": [
    "test_score = classifier.score(X_test_hashed, y_test)\n",
    "print(\"Test score: \", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test accuracy has gone up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
