{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest neighbor classifier \n",
    "\n",
    "if is a type of instance-based learning or non-generalizing learning. \n",
    "* does not attempt to construct a model \n",
    "* simply stores instances of the training data \n",
    "* classification is computed from a simple majority vote of the neighbors \n",
    "\n",
    "**KNeighborsClassifier** \n",
    "* learning based on k nearest neighbors \n",
    "* most commonly used \n",
    "* choice of k is highly data dependent \n",
    "\n",
    "hyperparameter \n",
    "* **n_neighbors** --> number of neighbors. default = 5\n",
    "* **weights** --> its better to weight the neighbors such that nearer neighbors contribute more to the fit \n",
    "    * *uniform* -> all points in each neighborhood are weighted equally\n",
    "    * *distance* -> weight points by the inverse of their distance. closer points higher weights.\n",
    "\n",
    "> we can define function as well which takes an array of distances as input and return an array of the sample shape containing the weights.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "knn_classifier = KNeighborsClassifier(\n",
    "    n_neighbors= 3, weights= 'uniform', algorithm= 'auto'\n",
    ")\n",
    "knn_classifier.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_weights(weights_array) : \n",
    "    return [weights_array[i] + (i*0.1) for i in range(len(weights_array))]  \n",
    "\n",
    "knn_classifier = KNeighborsClassifier(weights= user_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**algorithms**\n",
    "* ball_tree -> uses BallTree \n",
    "* kd_tree -> uses KDTree \n",
    "* brute -> brute force search \n",
    "* auto -> tries to find the best algo based the values passed in fit \n",
    "\n",
    "**leaf_size** --> for `ball_tree` and `kd_tree` we can specify. default 30. can affect the speed of construction and query as well as the memory required to store the tree \n",
    "\n",
    "**metric** -> distance metric to use for the tree, its either string or callable function. default `minkowski`. (euclidean, manhattan ...)\n",
    "\n",
    "**p** -> default 2. power parameter of minkowski metric. p= 1 ==> manhattan,p =2 ==> euclidean distance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RadiusNeighborsClassifier** \n",
    "* learning based on the number of neighbors within a fixed radius r of each training point \n",
    "* used where data is not uniformly sampled \n",
    "* fixed value of r is specified, such that points in sparser neighborhoods use fewer nearest neighbors for the classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "radius_classifier = RadiusNeighborsClassifier(\n",
    "    radius = 1.0, metric = 'minkowski', p = 2, \n",
    "    leaf_size = 30, algorithm = 'ball_tree'\n",
    ")\n",
    "radius_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
