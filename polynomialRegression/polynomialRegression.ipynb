{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to model polynomial regression \n",
    "* apply polynomial transformation on feature matrix \n",
    "* learn linear regression model on the transformed feature matrix\n",
    "\n",
    "\n",
    "> use pipeline --> apply polynomial transfrom --> apply linear regression <BR>\n",
    "> * for SGD with polynomial we just use SGD regressor in place of linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normal equation\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "poly_model = Pipeline([\n",
    "    (\"polynomial_feature\", PolynomialFeatures(degree = 2)), \n",
    "    (\"linear_regression\", LinearRegression())\n",
    "])\n",
    "\n",
    "poly_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient descent \n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "poly_model = Pipeline([\n",
    "    (\"polynomial_feature\", PolynomialFeatures(degree = 2)), \n",
    "    (\"sgd_regression\", SGDRegressor())\n",
    "])\n",
    "\n",
    "poly_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to keep interaction features and remove the higher deg features the we set `interaction_only = True` in polynomial feature transform\n",
    "\n",
    "```\n",
    "[x1, x2] --> [1, x1, x2, x1x2]\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "poly_transform = PolynomialFeatures(degree = 2, interaction_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### ridge regularization :\n",
    "\n",
    "<b> Option 1 : </b> \n",
    "1. instantiate obj of ridge estimator \n",
    "2. set parameter alpha(reg rate) to the specific param \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge \n",
    "ridge = Ridge(alpha = 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Option 2 : </b> \n",
    "1. instantiate SGD Regressor \n",
    "2. set parameter alpha to the req rate and `penalty = l2`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_ridge = SGDRegressor(penalty = 'l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Best reg parameter : \n",
    "<b> Option 1 : </b> \n",
    "search the best reg rate with built in cross validation in `RidgeCV` estimator \n",
    "<b> Option 2 : </b> \n",
    "use  cross validation with ridge or SVDReg to search the best reg rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ride + polynomial \n",
    "from sklearn.linear_model import Ridge \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "poly_model = Pipeline([\n",
    "    (\"polynomial_feature\", PolynomialFeatures(degree = 2)), \n",
    "    (\"ridge\", Ridge(alpha = 1e-3))\n",
    "])\n",
    "\n",
    "poly_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### lasso regularization :\n",
    "\n",
    "<b> Option 1 : </b> \n",
    "1. instantiate obj of lasso estimator \n",
    "2. set parameter alpha(reg rate) to the specific param \n",
    "\n",
    "<b> Option 2 : </b> \n",
    "1. instantiate SGD Regressor \n",
    "2. set parameter alpha to the req rate and `penalty = l1`\n",
    "\n",
    "### Best reg parameter : \n",
    "<b> Option 1 : </b> \n",
    "search the best reg rate with built in cross validation in `LassoCV` estimator \n",
    "<b> Option 2 : </b> \n",
    "use  cross validation with ridge or SVDReg to search the best reg rate \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sgd + lasso \n",
    "from sklearn.linear_model import SGDRegressor\n",
    "sgd_ridge = SGDRegressor(penalty = 'l1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso + polynomial \n",
    "from sklearn.linear_model import Lasso \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "poly_model = Pipeline([\n",
    "    (\"polynomial_feature\", PolynomialFeatures(degree = 2)), \n",
    "    (\"lasso\", Lasso(alpha = 1e-3))\n",
    "])\n",
    "\n",
    "poly_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Elastic net regularization :\n",
    "In the pipeline --> polynom transform --> `SGDRegressor(penalty = 'elastic net', l1_ration = 0.3)` <br> \n",
    "l2 ratio = 1 - l1 = 0.7\n",
    "\n",
    "* l1_ration = 1 --> l1 \n",
    "* l1_ration = 0 --> l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lasso + polynomial \n",
    "from sklearn.linear_model import SGDRegressor \n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "\n",
    "poly_model = Pipeline([\n",
    "    (\"polynomial_feature\", PolynomialFeatures(degree = 2)), \n",
    "    (\"elasticnet\", SGDRegressor(penalty= 'elasticnet', l1_ratio=0.3))\n",
    "]) \n",
    "\n",
    "poly_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "\n",
    "We select hyperparameters with the best cv score \n",
    "\n",
    "hyperparameter search consists of \n",
    "* an estimator \n",
    "* a parameter space \n",
    "* a method for searching or sampling candidates \n",
    "* a cross-validation scheme; \n",
    "* a score function\n",
    "\n",
    "\n",
    "<b>GridSearchCV</b> exhaustively considers all parameter combinations for specified values\n",
    "\n",
    "<b>RandomizedSearchCV</b> specifies distribution of parameter values and values are sampled from those distributions. \n",
    "Computational budget can be chosen independent of number of parameters and their possible values. specified in `n_iter` argument \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid search cv\n",
    "param_grid = [{\n",
    "    'c' : [1, 10, 100, 1000], \n",
    "    'kernel' : ['linear']\n",
    "        \n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random search cv\n",
    "param_dist = {\n",
    "    \"average\" : [True, False], \n",
    "    \"l1_ratio\" : stats.uniform(0, 1), \n",
    "    \"alpha\" : loguniform(1e-4, 1e0)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Steps : \n",
    "\n",
    "1. Divide training data into traning, validation and test sets.\n",
    "2. For each combination of hyper-parameter values learn a model with training set. \n",
    "> This step can be run in parallel by setting `n_jobs = -1` <br>\n",
    "> **NOTE :** Some param combinations may cause the search to fail. Set `error_score = 0 (or np.NaN)` to set score for the problematic fold to 0 and complete the search \n",
    "3. Evaluate performance of each model with validation set and select a model with the best evaluation score.\n",
    "4. Retrain model with the best hyper-parameter settings on training and validation set combined.\n",
    "5. Evaluate the model performance on the test set.\n",
    "\n",
    "\n",
    "#### Model specific HPT \n",
    "* Some models can fit data for a range of values of some parameter almost as efficiently as fitting the estimator for a single value of the parameter.\n",
    "* This feature can be leveraged to perform more efficient cv used for model selection of this parameter. \n",
    "    * linear_model.LassoCV\n",
    "    * linear_model.RidgeCV\n",
    "    * linear_model.ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline \n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.linear_model import SGDRegressor\n",
    "\n",
    "pararm_grid = [\n",
    "    {'poly__degree' : [2, 3, 4, 5, 6, 7, 8, 9]}\n",
    "]\n",
    "\n",
    "pipeline = Pipeline(steps = [\n",
    "    ('poly', PolynomialFeatures()), \n",
    "    ('sgd', SGDRegressor())\n",
    "])\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline, param_grid, cv = 5, \n",
    "    scoring= 'neg_mean_squared_error', return_train_score= True\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train.reshape(-1, 1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
