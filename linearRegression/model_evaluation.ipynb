{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1st we split the data and train the model on training set and check the model on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to evaluate model on worst case error\n",
    "max_error supports single output regression only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import max_error \n",
    "train_error = max_error(y_train, y_pred_train)\n",
    " \n",
    "test_error = max_error(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* training error --> emperical error \n",
    "* test error --> generalization error \n",
    "\n",
    "#### Evaluation metrics \n",
    "* **mean_absolute_error** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error \n",
    "eval_score = mean_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **mean_squarred_error** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squarred_error \n",
    "eval_score = mean_squarred_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **r2_score**  \n",
    "\n",
    "r2_score can be -ve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "eval_score = r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* **mean_squarred_log_error** \n",
    "\n",
    "useful for targets with exponential growths like populatio, sales growth. penalizes under estimation more than over estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squarred_log_error \n",
    "eval_score = mean_squarred_log_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **mean_absolute_percetage_error** \n",
    "\n",
    "sensitive to relative error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_percetage_error \n",
    "eval_score = mean_absolute_percetage_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **median_absolute_error** \n",
    "\n",
    "robust to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import median_absolute_error \n",
    "eval_score = median_absolute_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* score --> higher better \n",
    "* error --> lower better \n",
    "\n",
    "### Cross validation\n",
    "* KFold \n",
    "* RepeatedKfold \n",
    "* LeaveOneOut \n",
    "* ShuffleSplit \n",
    "\n",
    "\n",
    "#### KFold\n",
    "it uses 4 fold for training and 1 for evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validation_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "score = cross_validation_score(lin_reg, X, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validation_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "kfold_cv = KFold(n_splits = 5, random_state = 42)\n",
    "score = cross_validation_score(lin_reg, X, y, cv = kfold_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LeaveOneOut "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validation_score\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "loo_cv = LeaveOneOut()\n",
    "score = cross_validation_score(lin_reg, X, y, cv = loo_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = len(X) --> leave one out \n",
    "from sklearn.model_selection import cross_validation_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "n = X.shape[0]\n",
    "kfold_cv = KFold(n_splits = n)\n",
    "score = cross_validation_score(lin_reg, X, y, cv = kfold_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ShuffleSplit\n",
    "random permutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validation_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "shuffle_split_cv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 42)\n",
    "score = cross_validation_score(lin_reg, X, y, cv = shuffle_split_cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validation_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "shuffle_split_cv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 42)\n",
    "score = cross_validation_score(\n",
    "    lin_reg, X, y, cv = shuffle_split_cv, \n",
    "    scoring =  'neg_mean_absolute_error'   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test score for different folds\n",
    "\n",
    "* fit_time \n",
    "* score_time\n",
    "* test_score\n",
    "* estimator (optional)\n",
    "* train_score (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "cv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 42)\n",
    "cv_results = cross_validate(\n",
    "    regressor, data, target, cv = cv, \n",
    "    scoring = ['neg_mean_squared_error', 'neg_mean_absolute_error'], \n",
    "    return_train_score = True, return_estimator = True \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**study the effect of sample size on train and test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "results = learning_curve(\n",
    "    lin_reg, X_train, y_train, train_sizes = train_sizes, cv =cv, \n",
    "    scoring = 'neg_mean_squared_error'\n",
    ")\n",
    "train_size, train_score, test_score = results[:3]\n",
    "\n",
    "train_error, test_error = -train_score, -test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
